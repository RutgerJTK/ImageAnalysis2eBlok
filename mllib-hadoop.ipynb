{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
    "!tar -xvf spark-3.1.1-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# The enviromental settings are set\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"spark-3.1.1-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import isnan, when, count, col, lit\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd \n",
    "import numpy\n",
    "import matplotlib.pyplot as plt \n",
    "from pyspark.sql import SparkSession\n",
    "# create sparksession\n",
    "sc = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Pysparkexample\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is read\n",
    "data= sc.read.csv(\"data.csv\", inferSchema=True, header=True)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data filtration is done\n",
    "data.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A filtration step is applied to the data\n",
    "def replace(column, value):\n",
    "    return when(column != value, column).otherwise(lit(None))\n",
    "data = data.withColumn(\"Market Category\", replace(col(\"Market Category\"), \"N/A\"))\n",
    "data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in data.columns]).show()\n",
    "data = data.drop(\"Market Category\")\n",
    "data = data.na.drop()\n",
    "print((data.count(), len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is preprocessed to make it so the model can read it\n",
    "assembler = VectorAssembler(inputCols=[\"Year\",\n",
    "                                      \"Engine HP\",\n",
    "                                      \"Engine Cylinders\",\n",
    "                                      \"Number of Doors\",\n",
    "                                      \"highway MPG\",\n",
    "                                      \"city mpg\",\n",
    "                                      \"Popularity\"], outputCol = \"Attributes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model and pipeline are initialized\n",
    "regressor = RandomForestRegressor(featuresCol = \"Attributes\", labelCol=\"MSRP\")\n",
    "pipeline = Pipeline(stages=[assembler, regressor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The annotation pipeline is saved\n",
    "pipeline.write().overwrite().save(\"pipeline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And it's loaded again\n",
    "pipelineModel = Pipeline.load(\"pipeline\")\n",
    "paramGrid = ParamGridBuilder().addGrid(regressor.numTrees, [100, 500]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply cross validation in 3 folds to our model for better results\n",
    "crossval = CrossValidator(estimator=pipelineModel,\n",
    "estimatorParamMaps = paramGrid,\n",
    "evaluator= RegressionEvaluator(labelCol = \"MSRP\"),\n",
    "                               numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 80/20 train test split is made\n",
    "train_data, test_data = data.randomSplit([0.8,0.2], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we train the model\n",
    "cvModel= crossval.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best model is selected, as cross validation was applied\n",
    "bestModel= cvModel.bestModel\n",
    "for x in range(len(bestModel.stages)):\n",
    "    print(bestModel.stages[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We predict values on the test set for evaluation\n",
    "pred = cvModel.transform(test_data)\n",
    "pred.select(\"MSRP\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we evaluate the model\n",
    "eval = RegressionEvaluator(labelCol = \"MSRP\")\n",
    "rmse = eval.evaluate(pred)\n",
    "mse= eval.evaluate(pred, {eval.metricName: \"mse\"})\n",
    "mae= eval.evaluate(pred, {eval.metricName: \"mae\"})\n",
    "r2 = eval.evaluate(pred, {eval.metricName: \"r2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"metrics.txt\", \"w\").write(\"{}\\n{}\\n{}\\n{}\\n\".format(rmse, mse, mae,r2))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "N6ZDpd9XzFeN"
   ],
   "name": "Text classification with TF-Hub",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python387jvsc74a57bd0d6121a2be9be14c350818965fb41ffcfa13bfc075c0f01a5a51b266cf1a319be",
   "display_name": "Python 3.8.7 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "d6121a2be9be14c350818965fb41ffcfa13bfc075c0f01a5a51b266cf1a319be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}